import { useRef, useCallback, useEffect } from "react";
import { Platform } from "react-native";
import { Audio } from "expo-av";
import * as Haptics from "expo-haptics";

// ‚úÖ NOUVEAU: Interface pour g√©rer l'√©tat audio web
interface WebAudioState {
  context: AudioContext | null;
  isSupported: boolean;
  isInitialized: boolean;
  userHasInteracted: boolean;
  lastError: string | null;
}

// ‚úÖ NOUVEAU: Types de son avec param√®tres
interface SoundConfig {
  frequency: number;
  duration: number;
  volume: number;
  type: OscillatorType;
}

// ‚úÖ NOUVEAU: Configuration des sons
const SOUND_CONFIGS: Record<"start" | "stop" | "end", SoundConfig> = {
  start: { frequency: 800, duration: 200, volume: 0.1, type: "sine" },
  stop: { frequency: 400, duration: 200, volume: 0.1, type: "sine" },
  end: { frequency: 1000, duration: 800, volume: 0.15, type: "sine" },
};

export const useAudio = () => {
  const startSoundRef = useRef<Audio.Sound | null>(null);
  const stopSoundRef = useRef<Audio.Sound | null>(null);
  const endSoundRef = useRef<Audio.Sound | null>(null);

  // ‚úÖ NOUVEAU: √âtat audio web s√©curis√©
  const webAudioStateRef = useRef<WebAudioState>({
    context: null,
    isSupported: false,
    isInitialized: false,
    userHasInteracted: false,
    lastError: null,
  });

  // ‚úÖ NOUVEAU: D√©tection s√©curis√©e du support Web Audio
  const checkWebAudioSupport = useCallback((): boolean => {
    // V√©rification de l'environnement
    if (typeof window === "undefined" || typeof document === "undefined") {
      console.log("üåê [Audio] Environnement non-web d√©tect√©");
      return false;
    }

    try {
      // V√©rification de l'existence de AudioContext
      const AudioContextClass =
        (window as any).AudioContext ||
        (window as any).webkitAudioContext ||
        (window as any).mozAudioContext ||
        (window as any).msAudioContext;

      if (!AudioContextClass) {
        console.log("üö´ [Audio] AudioContext non support√©");
        return false;
      }

      // Test de cr√©ation (sans l'utiliser)
      try {
        const testContext = new AudioContextClass();
        if (testContext.close) {
          testContext.close().catch(() => {
            // Ignore les erreurs de fermeture
          });
        }
        console.log("‚úÖ [Audio] Web Audio API support√©");
        return true;
      } catch (testError) {
        console.log("‚ùå [Audio] √âchec cr√©ation AudioContext:", testError);
        return false;
      }
    } catch (error) {
      console.log("‚ùå [Audio] Erreur d√©tection Web Audio:", error);
      return false;
    }
  }, []);

  // ‚úÖ NOUVEAU: Cr√©ation s√©curis√©e d'AudioContext
  const createAudioContext = useCallback((): AudioContext | null => {
    const state = webAudioStateRef.current;

    // Si d√©j√† initialis√©, retourner l'instance existante
    if (state.context && state.context.state !== "closed") {
      return state.context;
    }

    try {
      if (!state.isSupported) {
        console.log("üö´ [Audio] Web Audio non support√©, skip cr√©ation");
        return null;
      }

      const AudioContextClass =
        (window as any).AudioContext || (window as any).webkitAudioContext;

      if (!AudioContextClass) {
        console.log("‚ùå [Audio] AudioContext non disponible");
        return null;
      }

      const context = new AudioContextClass();

      // ‚úÖ Gestion de l'autoplay policy moderne
      if (context.state === "suspended") {
        console.log("‚è∏Ô∏è [Audio] AudioContext suspendu (autoplay policy)");
        // Ne pas essayer de r√©sumer automatiquement
        // Attendre l'interaction utilisateur
      }

      // Sauvegarder l'instance
      webAudioStateRef.current = {
        ...state,
        context,
        isInitialized: true,
        lastError: null,
      };

      console.log("‚úÖ [Audio] AudioContext cr√©√©, √©tat:", context.state);
      return context;
    } catch (error) {
      const errorMessage =
        error instanceof Error ? error.message : "Erreur inconnue";
      console.error("‚ùå [Audio] Erreur cr√©ation AudioContext:", errorMessage);

      webAudioStateRef.current = {
        ...state,
        context: null,
        lastError: errorMessage,
      };

      return null;
    }
  }, []);

  // ‚úÖ NOUVEAU: Activation s√©curis√©e apr√®s interaction utilisateur
  const resumeAudioContext = useCallback(async (): Promise<boolean> => {
    const state = webAudioStateRef.current;

    if (!state.context) {
      console.log("üö´ [Audio] Pas de contexte audio √† reprendre");
      return false;
    }

    try {
      if (state.context.state === "suspended") {
        console.log("‚ñ∂Ô∏è [Audio] Reprise du contexte audio...");
        await state.context.resume();

        webAudioStateRef.current = {
          ...state,
          userHasInteracted: true,
        };

        console.log(
          "‚úÖ [Audio] Contexte audio repris, √©tat:",
          state.context.state
        );
        return true;
      }

      return state.context.state === "running";
    } catch (error) {
      console.error("‚ùå [Audio] Erreur reprise contexte:", error);
      return false;
    }
  }, []);

  // ‚úÖ NOUVEAU: G√©n√©ration de son web s√©curis√©e
  const playWebSound = useCallback(
    async (config: SoundConfig): Promise<boolean> => {
      try {
        const context = createAudioContext();
        if (!context) {
          console.log("üö´ [Audio] Pas de contexte audio disponible");
          return false;
        }

        // Essayer de reprendre le contexte si suspendu
        if (context.state === "suspended") {
          const resumed = await resumeAudioContext();
          if (!resumed) {
            console.log(
              "‚è∏Ô∏è [Audio] Impossible de reprendre le contexte (autoplay)"
            );
            return false;
          }
        }

        // V√©rifier que le contexte est actif
        if (context.state !== "running") {
          console.log("‚èπÔ∏è [Audio] Contexte audio non actif:", context.state);
          return false;
        }

        console.log(`üîä [Audio] G√©n√©ration son:`, {
          frequency: config.frequency,
          duration: config.duration,
          volume: config.volume,
        });

        // Cr√©er les n≈ìuds audio
        const oscillator = context.createOscillator();
        const gainNode = context.createGain();

        // Configuration de l'oscillateur
        oscillator.frequency.value = config.frequency;
        oscillator.type = config.type;

        // Configuration du volume avec fade out
        const now = context.currentTime;
        const endTime = now + config.duration / 1000;

        gainNode.gain.setValueAtTime(config.volume, now);
        gainNode.gain.exponentialRampToValueAtTime(0.001, endTime);

        // Connexion des n≈ìuds
        oscillator.connect(gainNode);
        gainNode.connect(context.destination);

        // D√©marrage et arr√™t programm√©
        oscillator.start(now);
        oscillator.stop(endTime);

        console.log("‚úÖ [Audio] Son g√©n√©r√© avec succ√®s");
        return true;
      } catch (error) {
        const errorMessage =
          error instanceof Error ? error.message : "Erreur inconnue";
        console.error("‚ùå [Audio] Erreur g√©n√©ration son:", errorMessage);

        // Sauvegarder l'erreur pour debug
        webAudioStateRef.current = {
          ...webAudioStateRef.current,
          lastError: errorMessage,
        };

        return false;
      }
    },
    [createAudioContext, resumeAudioContext]
  );

  // ‚úÖ AM√âLIORATION: Fonction de fallback haptic am√©lior√©e
  const playHapticFallback = useCallback(
    async (type: "start" | "stop" | "end"): Promise<void> => {
      if (Platform.OS === "web") {
        console.log("üåê [Audio] Fallback web - pas de vibration disponible");
        return;
      }

      try {
        switch (type) {
          case "start":
            await Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Medium);
            break;
          case "stop":
            await Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Light);
            break;
          case "end":
            await Haptics.notificationAsync(
              Haptics.NotificationFeedbackType.Success
            );
            // Double vibration pour attirer l'attention
            setTimeout(() => {
              Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Heavy);
            }, 300);
            break;
        }
        console.log(`üì≥ [Audio] Vibration ${type} ex√©cut√©e`);
      } catch (error) {
        console.log("‚ùå [Audio] Erreur vibration:", error);
      }
    },
    []
  );

  // ‚úÖ FONCTION PRINCIPALE: Initialisation s√©curis√©e des sons
  const loadSounds = useCallback(async () => {
    console.log("üîÑ [Audio] Initialisation du syst√®me audio...");

    try {
      // Sur web, v√©rifier le support
      if (Platform.OS === "web") {
        const isSupported = checkWebAudioSupport();
        webAudioStateRef.current = {
          ...webAudioStateRef.current,
          isSupported,
        };

        if (isSupported) {
          // Pr√©-cr√©er le contexte (sans l'activer)
          createAudioContext();
          console.log(
            "‚úÖ [Audio] Web Audio initialis√© (suspendu jusqu'√† interaction)"
          );
        } else {
          console.log(
            "‚ÑπÔ∏è [Audio] Web Audio non support√©, utilisation des vibrations uniquement"
          );
        }
        return;
      }

      // Sur mobile, configurer Expo Audio
      if (!Audio || !Audio.setAudioModeAsync) {
        console.log("üì± [Audio] API Audio Expo non disponible");
        return;
      }

      await Audio.setAudioModeAsync({
        allowsRecordingIOS: false,
        staysActiveInBackground: false,
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
      });

      console.log("‚úÖ [Audio] Expo Audio configur√©");
    } catch (error: any) {
      console.log(
        "‚ö†Ô∏è [Audio] Erreur initialisation:",
        error?.message || "Erreur inconnue"
      );
    }
  }, [checkWebAudioSupport, createAudioContext]);

  // ‚úÖ FONCTION PRINCIPALE: Lecture de son s√©curis√©e
  const playSound = useCallback(
    async (type: "start" | "stop" | "end") => {
      console.log(`üéµ [Audio] Demande lecture son: ${type}`);

      try {
        // Sur web, essayer Web Audio API
        if (Platform.OS === "web") {
          const state = webAudioStateRef.current;

          if (state.isSupported) {
            const config = SOUND_CONFIGS[type];
            const success = await playWebSound(config);

            if (success) {
              console.log(`‚úÖ [Audio] Son ${type} jou√© via Web Audio`);
              return;
            } else {
              console.log(
                `‚ö†Ô∏è [Audio] √âchec Web Audio, pas de fallback sur web`
              );
              return;
            }
          } else {
            console.log(
              `‚ÑπÔ∏è [Audio] Web Audio non support√©, son ${type} ignor√©`
            );
            return;
          }
        }

        // Sur mobile, essayer les sons Expo puis vibrations
        let sound = null;
        switch (type) {
          case "start":
            sound = startSoundRef.current;
            break;
          case "stop":
            sound = stopSoundRef.current;
            break;
          case "end":
            sound = endSoundRef.current;
            break;
        }

        if (sound) {
          await sound.replayAsync();
          console.log(`‚úÖ [Audio] Son ${type} jou√© via Expo Audio`);
        } else {
          console.log(
            `üì≥ [Audio] Son ${type} non disponible, utilisation vibration`
          );
          await playHapticFallback(type);
        }
      } catch (error: any) {
        const errorMessage = error?.message || "Erreur inconnue";
        console.log(`‚ùå [Audio] Erreur lecture son ${type}:`, errorMessage);

        // Fallback vers vibrations sur mobile
        if (Platform.OS !== "web") {
          console.log(`üì≥ [Audio] Fallback vibration pour ${type}`);
          await playHapticFallback(type);
        }
      }
    },
    [playWebSound, playHapticFallback]
  );

  // ‚úÖ NOUVEAU: Fonction pour activer l'audio apr√®s interaction utilisateur
  const enableAudioAfterInteraction =
    useCallback(async (): Promise<boolean> => {
      if (Platform.OS !== "web") {
        return true; // Pas n√©cessaire sur mobile
      }

      const state = webAudioStateRef.current;

      if (!state.isSupported) {
        console.log("üö´ [Audio] Web Audio non support√©");
        return false;
      }

      if (state.userHasInteracted) {
        console.log("‚úÖ [Audio] Utilisateur a d√©j√† interagi");
        return true;
      }

      console.log("üëÜ [Audio] Activation apr√®s interaction utilisateur...");
      return await resumeAudioContext();
    }, [resumeAudioContext]);

  // ‚úÖ FONCTION DE NETTOYAGE: S√©curis√©e
  const cleanupSounds = useCallback(() => {
    console.log("üßπ [Audio] Nettoyage des ressources audio...");

    try {
      // Nettoyage des sons Expo
      const sounds = [
        startSoundRef.current,
        stopSoundRef.current,
        endSoundRef.current,
      ];
      sounds.forEach((sound, index) => {
        if (sound) {
          sound.unloadAsync().catch((error) => {
            console.warn(`‚ö†Ô∏è [Audio] Erreur d√©chargement son ${index}:`, error);
          });
        }
      });

      // Nettoyage du contexte web
      if (Platform.OS === "web") {
        const state = webAudioStateRef.current;
        if (state.context && state.context.state !== "closed") {
          state.context.close().catch((error) => {
            console.warn("‚ö†Ô∏è [Audio] Erreur fermeture AudioContext:", error);
          });
        }

        // Reset de l'√©tat
        webAudioStateRef.current = {
          context: null,
          isSupported: false,
          isInitialized: false,
          userHasInteracted: false,
          lastError: null,
        };
      }

      console.log("‚úÖ [Audio] Nettoyage termin√©");
    } catch (error) {
      console.error("‚ùå [Audio] Erreur lors du nettoyage:", error);
    }
  }, []);

  // ‚úÖ NOUVEAU: Fonction pour obtenir l'√©tat audio (debug)
  const getAudioState = useCallback(() => {
    if (Platform.OS === "web") {
      return {
        platform: "web",
        ...webAudioStateRef.current,
        contextState: webAudioStateRef.current.context?.state || "no-context",
      };
    }
    return {
      platform: Platform.OS,
      expoAudioAvailable: !!Audio,
    };
  }, []);

  // ‚úÖ EFFET: Nettoyage automatique lors du d√©montage
  useEffect(() => {
    return () => {
      cleanupSounds();
    };
  }, [cleanupSounds]);

  // ‚úÖ EFFET: √âcoute des interactions utilisateur sur web
  useEffect(() => {
    if (Platform.OS !== "web") return;

    const handleUserInteraction = () => {
      const state = webAudioStateRef.current;

      if (state.isSupported && !state.userHasInteracted) {
        console.log("üëÜ [Audio] Premi√®re interaction utilisateur d√©tect√©e");
        enableAudioAfterInteraction();
      }
    };

    // √âcouter les √©v√©nements d'interaction
    const events = ["click", "touchstart", "keydown"];
    events.forEach((event) => {
      document.addEventListener(event, handleUserInteraction, {
        once: true,
        passive: true,
      });
    });

    return () => {
      events.forEach((event) => {
        document.removeEventListener(event, handleUserInteraction);
      });
    };
  }, [enableAudioAfterInteraction]);

  return {
    loadSounds,
    playSound,
    cleanupSounds,
    enableAudioAfterInteraction,
    getAudioState,
  };
};
